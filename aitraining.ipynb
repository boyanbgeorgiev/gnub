{"cells":[{"cell_type":"markdown","metadata":{},"source":["Biblioteki"]},{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","import cv2\n","import os"]},{"cell_type":"markdown","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"source":["Globalni Konstanti"]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"d157dc1311928d1ada13ed2ef4a34c4ea5c0b538","trusted":true},"outputs":[],"source":["NUM_CLASSES = 14\n","CHANNELS = 3\n","IMAGE_RESIZE = 75\n","RESNET50_POOLING_AVERAGE = 'avg'\n","DENSE_LAYER_ACTIVATION = 'softmax'\n","OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n","LOSS_METRICS = ['accuracy']\n","NUM_EPOCHS = 10\n","EARLY_STOP_PATIENCE = 3\n","STEPS_PER_EPOCH_TRAINING = 10\n","STEPS_PER_EPOCH_VALIDATION= 10\n","BATCH_SIZE_TRAINING = 100\n","BATCH_SIZE_VALIDATION = 100\n","BATCH_SIZE_TESTING = 1"]},{"cell_type":"markdown","metadata":{"_uuid":"b651539464d36c7443a601e914479f0d2153f435"},"source":["ResNet50"]},{"cell_type":"code","execution_count":29,"metadata":{"_uuid":"2fc47c3f887e6713b5a2be38c02b38a8ec80bf97","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.16.1\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"]},{"cell_type":"markdown","metadata":{"_uuid":"4ebad39fff164624f5616a83cd8831308431da7d"},"source":["### Define Our Transfer Learning Network Model Consisting of 2 Layers\n","\n","Here, we are preparing specification or blueprint of the TensorFlow DAG (directed acyclcic graph) for just the MODEL part."]},{"cell_type":"code","execution_count":30,"metadata":{"_uuid":"0bb4a8eccd70874ef21f0809f478f993fa127fb2","trusted":true},"outputs":[{"ename":"ValueError","evalue":"The `weights` argument should be either `None` (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRESNET50_POOLING_AVERAGE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresnet_weights_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(NUM_CLASSES, activation \u001b[38;5;241m=\u001b[39m DENSE_LAYER_ACTIVATION))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\applications\\resnet.py:406\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    403\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\applications\\resnet.py:109\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    A Model instance.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (weights \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;129;01mor\u001b[39;00m file_utils\u001b[38;5;241m.\u001b[39mexists(weights)):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.  Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using `weights=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` with `include_top=True`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5"]}],"source":["#Still not talking about our train/test data or any pre-processing.\n","\n","model = Sequential()\n","\n","# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n","model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n","\n","# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n","model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n","\n","# Say not to train first layer (ResNet) model as it is already trained\n","model.layers[0].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b617a28f0f89b272a0aa2af6cf72f2dd642ee052","trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"_uuid":"3587981a5b6b1d6ff8221738d51d78cafb2dd02c"},"source":["### Compile Our Transfer Learning Model"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"670238611770f43a056332cc06efff44e20ad124","trusted":true},"outputs":[],"source":["from tensorflow.python.keras import optimizers\n","\n","sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n","model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"]},{"cell_type":"markdown","metadata":{"_uuid":"8d003a99fe4ff58b8905c7f6b5286d97a852cb7a"},"source":["### Prepare Keras Data Generators\n","\n","Keras *ImageDataGenerator(...)* generates batches of tensor image data with real-time data augmentation. The data will be looped over (in batches). It is useful with large dataset to source, pre-process (resize, color conversion, image augmentation, batch normalize) & supply resulting images in batches to downstream Keras modeling components, namely *fit_generator(...)* & *predict_generator(...)* -vs- *fit(...)* & *predict(...)* for small dataset.\n","\n","Kaggle competition rule expects Dog & Cat to be labeled as 1 & 0. Keras >> ImageDataGenerator >> flow_from_directory takes in 'classes' list for mapping it to LABEL indices otherwise treats sub-folders enumerated classes in alphabetical order, i.e., Cat is 0 & Dog is 1."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ac9ebd909fee81c8c8d9b9fccb6590944d8106eb","trusted":true},"outputs":[],"source":["from keras.applications.resnet50 import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","image_size = IMAGE_RESIZE\n","\n","# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n","# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n","# Batch Normalization helps in faster convergence\n","data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n","# Both train & valid folders must have NUM_CLASSES sub-folders\n","train_generator = data_generator.flow_from_directory(\n","        '../input/catsdogs-trainvalid-80pc-prepd/trainvalidfull4keras/trainvalidfull4keras/train',\n","        target_size=(image_size, image_size),\n","        batch_size=BATCH_SIZE_TRAINING,\n","        class_mode='categorical')\n","\n","validation_generator = data_generator.flow_from_directory(\n","        '../input/catsdogs-trainvalid-80pc-prepd/trainvalidfull4keras/trainvalidfull4keras/valid',\n","        target_size=(image_size, image_size),\n","        batch_size=BATCH_SIZE_VALIDATION,\n","        class_mode='categorical') "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5014f91b6aeae661f0bc5db5d546089a07ca5b9d","trusted":true},"outputs":[],"source":["# Max number of steps that these generator will have opportunity to process their source content\n","# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n","# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n","(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"]},{"cell_type":"markdown","metadata":{"_uuid":"f56e7cf9eae4c86c72468e322e7f00859a2ce9cd"},"source":["### Train Our Model With Cats & Dogs Train (splitted) Data Set"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2dfad78129d725f42110cde0270c32d7373d6d1d","trusted":true},"outputs":[],"source":["# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n","cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d108d3598210930bab431f43c6865488b01d467b","trusted":true},"outputs":[],"source":["# Grid Search is an ideal candidate for distributed machine learning\n","# Pseudo code for hyperparameters Grid Search\n","\n","'''\n","from sklearn.grid_search import ParameterGrid\n","param_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\n","\n","grid = ParameterGrid(param_grid)\n","\n","# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\n","for params in grid:\n","    print(params)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cf85fe3c0653aa56503b7da058ea8acf445eec6e","trusted":true},"outputs":[],"source":["fit_history = model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n","        epochs = NUM_EPOCHS,\n","        validation_data=validation_generator,\n","        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n","        callbacks=[cb_checkpointer, cb_early_stopper]\n",")\n","model.load_weights(\"../working/best.hdf5\")"]},{"cell_type":"markdown","metadata":{"_uuid":"1ef4dd95f6d12f9277255576645e8bfce5270b81"},"source":["### Training Metrics\n","\n","One of the default callbacks that is registered when training all deep learning models is the History callback. It records training metrics (training accuracy, training loss, validation loss & validation accuracy) for each epoch. Note that training accuracy & loss during epoch steps are somewhat incomplete information and they are not recorded in history.\n","\n","Observe that training uses early stopping, hence metrics is available for epochs run, not for NUM_EPOCHS."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"383d7a0aa87e1508a46fcebfcd5a80d7aafb840f","trusted":true},"outputs":[],"source":["print(fit_history.history.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"00e51568f7e6022c6738c0e1a41080bc7152c257","trusted":true},"outputs":[],"source":[" plt.figure(1, figsize = (15,8)) \n","    \n","plt.subplot(221)  \n","plt.plot(fit_history.history['acc'])  \n","plt.plot(fit_history.history['val_acc'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","    \n","plt.subplot(222)  \n","plt.plot(fit_history.history['loss'])  \n","plt.plot(fit_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'valid']) \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3941e7c5d983e2ad6ae6d6da0a1415ea27e1db7e","trusted":true},"outputs":[],"source":["# NOTE that flow_from_directory treats each sub-folder as a class which works fine for training data\n","# Actually class_mode=None is a kind of workaround for test data which too must be kept in a subfolder\n","\n","# batch_size can be 1 or any factor of test dataset size to ensure that test dataset is samples just once, i.e., no data is left out\n","test_generator = data_generator.flow_from_directory(\n","    directory = '../input/test-files-prepd/test4keras/test4keras',\n","    target_size = (image_size, image_size),\n","    batch_size = BATCH_SIZE_TESTING,\n","    class_mode = None,\n","    shuffle = False,\n","    seed = 123\n",")\n","\n","# Try batch size of 1+ in test_generator & check batch_index & filenames in resulting batches\n","'''\n","for i in test_generator:\n","    #print(test_generator.batch_index, test_generator.batch_size)\n","    idx = (test_generator.batch_index - 1) * test_generator.batch_size\n","    print(test_generator.filenames[idx : idx + test_generator.batch_size])\n","'''"]},{"cell_type":"markdown","metadata":{"_uuid":"8c6e7f35552f87b522aa32397ffb71ea732ce80b","trusted":true},"source":["### Observe Prediction Time With Different Batch Size\n","\n","With GPU, 97s for full prediction with batch_size=100 -vs- 264s with 1. But note that to avoid ImageDataGenerator iterator repeatability, we need to use 1 as batch_size."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9911ff38ec4b82f5282f078aae63b2a510a9a6cc","trusted":true},"outputs":[],"source":["# Reset before each call to predict\n","test_generator.reset()\n","\n","pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n","\n","predicted_class_indices = np.argmax(pred, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e54bc22bd1a2af7d704f9164b624b79b8cbd4f56","trusted":true},"outputs":[],"source":["TEST_DIR = '../input/test-files-prepd/test4keras/test4keras/'\n","f, ax = plt.subplots(5, 5, figsize = (15, 15))\n","\n","for i in range(0,25):\n","    imgBGR = cv2.imread(TEST_DIR + test_generator.filenames[i])\n","    imgRGB = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB)\n","    \n","    # a if condition else b\n","    predicted_class = \"Dog\" if predicted_class_indices[i] else \"Cat\"\n","\n","    ax[i//5, i%5].imshow(imgRGB)\n","    ax[i//5, i%5].axis('off')\n","    ax[i//5, i%5].set_title(\"Predicted:{}\".format(predicted_class))    \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"39bac850385ba7129c97c1c0d389b36e7f2f0dfe","trusted":true},"outputs":[],"source":["results_df = pd.DataFrame(\n","    {\n","        'id': pd.Series(test_generator.filenames), \n","        'label': pd.Series(predicted_class_indices)\n","    })\n","results_df['id'] = results_df.id.str.extract('(\\d+)')\n","results_df['id'] = pd.to_numeric(results_df['id'], errors = 'coerce')\n","results_df.sort_values(by='id', inplace = True)\n","\n","results_df.to_csv('submission.csv', index=False)\n","results_df.head()"]},{"cell_type":"markdown","metadata":{"_uuid":"2e5600300a330725b29c74c813135144a22cee56"},"source":["### Keras Limitations\n","\n","* [10/02/2018] The *validation_split* is not supported in *fit_generator*, hence its expects ImageDataGenerator for pre-splitted train & valid.\n","* [10/02/2018] Model learning through *fit_generator* is not compatible for Sklearn *GridSearchCV* again *mostly* due to no support for *validation_split*."]},{"cell_type":"markdown","metadata":{"_uuid":"60a34703bd652a314983948d93ee2dfe6d760ec3"},"source":["### Followup Plan\n","\n","1. Scale and pad and avoid aspect ratio change of original image through Keras ImageDataGenerator pre-processing insfrastructure\n","2. Image augmentation\n","3. Pipeline\n","4. Distributed ML for Grid Search on Spark Cluster"]},{"cell_type":"markdown","metadata":{"_uuid":"422beefc8f408582e85292cec3fe8225228f2ab5"},"source":["### References\n","\n","1. [Transfer Learning by Dan B](https://www.kaggle.com/dansbecker/transfer-learning)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":38425,"sourceId":5441,"sourceType":"competition"},{"datasetId":6209,"sourceId":9900,"sourceType":"datasetVersion"},{"datasetId":57539,"sourceId":110819,"sourceType":"datasetVersion"},{"datasetId":57578,"sourceId":110930,"sourceType":"datasetVersion"}],"dockerImageVersionId":11105,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
